<!-- ## **HunyuanVideo** -->

[English Version](./README.md)

<p align="center">
  <img src="./assets/logo.png"  height=100>
</p>

# **HunyuanVideo-I2V** ğŸŒ…

<div align="center">
  <a href="https://github.com/Tencent/HunyuanVideo-I2V"><img src="https://img.shields.io/static/v1?label=HunyuanVideo-I2V ä»£ç &message=Github&color=blue"></a> &ensp;
  <a href="https://aivideo.hunyuan.tencent.com"><img src="https://img.shields.io/static/v1?label=é¡¹ç›®ä¸»é¡µ&message=Web&color=green"></a> &ensp;
  <a href="https://video.hunyuan.tencent.com"><img src="https://img.shields.io/static/v1?label=åœ¨çº¿ä½“éªŒ&message=Web&color=green"></a>
</div>
<div align="center">
  <a href="https://arxiv.org/abs/2412.03603"><img src="https://img.shields.io/static/v1?label=æŠ€æœ¯æŠ¥å‘Š&message=Arxiv&color=red"></a> &ensp;
  <a href="https://aivideo.hunyuan.tencent.com/hunyuanvideo.pdf"><img src="https://img.shields.io/static/v1?label=æŠ€æœ¯æŠ¥å‘Š&message=é«˜æ¸…ç‰ˆæœ¬ (~350M)&color=red"></a>
</div>
<div align="center">
  <a href="https://huggingface.co/tencent/HunyuanVideo-I2V"><img src="https://img.shields.io/static/v1?label=HunyuanVideo-I2V&message=HuggingFace&color=yellow"></a> &ensp;
</div>

<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„<a href="assets/WECHAT.md" target="_blank">å¾®ä¿¡ç¤¾åŒº</a>å’Œ<a href="https://discord.gg/tv7FkG4Nwf" target="_blank">Discord</a> 
</p>

-----

ç»§æˆ‘ä»¬æˆåŠŸå¼€æº[HunyuanVideo](https://github.com/Tencent/HunyuanVideo)åï¼Œæˆ‘ä»¬å¾ˆé«˜å…´æ¨å‡º[HunyuanVideo-I2V](https://github.com/Tencent/HunyuanVideo-I2V)ï¼Œä¸€ä¸ªæ–°çš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼ŒåŠ é€Ÿå¼€æºç¤¾åŒºçš„æ¢ç´¢ï¼

æœ¬ä»“åº“åŒ…å«å®˜æ–¹PyTorchæ¨¡å‹å®šä¹‰ã€é¢„è®­ç»ƒæƒé‡åŠæ¨ç†/é‡‡æ ·ä»£ç ã€‚æ›´å¤šå¯è§†åŒ–æ•ˆæœè¯·è®¿é—®[é¡¹ç›®ä¸»é¡µ](https://aivideo.hunyuan.tencent.com)ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å‘å¸ƒäº†LoRAè®­ç»ƒä»£ç ï¼Œç”¨äºå®šåˆ¶åŒ–ç‰¹æ•ˆç”Ÿæˆï¼Œå¯åˆ›å»ºæ›´æœ‰è¶£çš„è§†é¢‘æ•ˆæœã€‚

> [**HunyuanVideo: A Systematic Framework For Large Video Generation Model**](https://arxiv.org/abs/2412.03603)

## ğŸ”¥ğŸ”¥ğŸ”¥ æœ€æ–°åŠ¨æ€
* 2025å¹´3æœˆ6æ—¥: ğŸ‘‹ å‘å¸ƒHunyuanVideo-I2Vçš„æ¨ç†ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚[ä¸‹è½½åœ°å€](https://github.com/Tencent/HunyuanVideo-I2V/blob/main/ckpts/README.md)

## ğŸ¥ æ¼”ç¤º
### I2V ç¤ºä¾‹
<div align="center">
  <video src="https://github.com/user-attachments/assets/442afb73-3092-454f-bc46-02361c285930" width="80%" poster="./assets/video_poster.jpg"> </video>
  <p>è”åˆåˆ›ä½œ @D-aiY å¯¼æ¼” ä¸ä¸€</p>
</div>

### å®šåˆ¶åŒ–I2V LoRAæ•ˆæœæ¼”ç¤º

| ç‰¹æ•ˆç±»å‹       |  å‚è€ƒå›¾åƒ  | ç”Ÿæˆè§†é¢‘  |
|:---------------:|:--------------------------------:|:----------------:|
|   å¤´å‘ç”Ÿé•¿   |        <img src="./assets/demo/i2v_lora/imgs/hair_growth.png" width="40%">         |       <video src="https://github.com/user-attachments/assets/06b998ae-bbde-4c1f-96cb-a25a9197d5cb" width="100%"> </video>        |
|     æ‹¥æŠ±     |      <img src="./assets/demo/i2v_lora/imgs/embrace.png" width="40%">          |       <video src="https://github.com/user-attachments/assets/f8c99eb1-2a43-489a-ba02-6bd50a6dd260" width="100%" > </video>        |

## ğŸ“‘ å¼€æºè®¡åˆ’
- HunyuanVideo-I2Vï¼ˆå›¾åƒåˆ°è§†é¢‘æ¨¡å‹ï¼‰
  - [x] LoRAè®­ç»ƒè„šæœ¬
  - [x] æ¨ç†ä»£ç 
  - [x] æ¨¡å‹æƒé‡
  - [x] ComfyUIæ”¯æŒ
  - [ ] å¤šGPUåºåˆ—å¹¶è¡Œæ¨ç†ï¼ˆæå‡å¤šå¡æ¨ç†é€Ÿåº¦ï¼‰
  - [ ] Diffusersé›†æˆ 
  - [ ] FP8é‡åŒ–æƒé‡

## ç›®å½•
- [**HunyuanVideo-I2V** ğŸŒ…](#hunyuanvideo-i2v-)
  - [ğŸ”¥ğŸ”¥ğŸ”¥ æœ€æ–°åŠ¨æ€](#-æœ€æ–°åŠ¨æ€)
  - [ğŸ¥ æ¼”ç¤º](#-æ¼”ç¤º)
    - [I2V ç¤ºä¾‹](#i2v-ç¤ºä¾‹)
    - [å®šåˆ¶åŒ–I2V LoRAæ•ˆæœæ¼”ç¤º](#å®šåˆ¶åŒ–i2v-loraæ•ˆæœæ¼”ç¤º)
  - [ğŸ“‘ å¼€æºè®¡åˆ’](#-å¼€æºè®¡åˆ’)
  - [ç›®å½•](#ç›®å½•)
  - [**HunyuanVideo-I2V æ•´ä½“æ¶æ„**](#hunyuanvideo-i2v-æ•´ä½“æ¶æ„)
  - [ğŸ“œ è¿è¡Œè¦æ±‚](#-è¿è¡Œè¦æ±‚)
  - [ğŸ› ï¸ ä¾èµ–å®‰è£…](#ï¸-ä¾èµ–å®‰è£…)
    - [Linux å®‰è£…æŒ‡å¼•](#linux-å®‰è£…æŒ‡å¼•)
  - [ğŸ§± ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹](#-ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹)
  - [ğŸ”‘ å• GPU æ¨ç†](#-å•-gpu-æ¨ç†)
    - [ä½¿ç”¨å›¾ç”Ÿè§†é¢‘æ¨¡å‹çš„å»ºè®®](#ä½¿ç”¨å›¾ç”Ÿè§†é¢‘æ¨¡å‹çš„å»ºè®®)
    - [ä½¿ç”¨å‘½ä»¤è¡Œ](#ä½¿ç”¨å‘½ä»¤è¡Œ)
    - [æ›´å¤šé…ç½®](#æ›´å¤šé…ç½®)
  - [ğŸ‰è‡ªå®šä¹‰ I2V LoRA æ•ˆæœè®­ç»ƒ](#è‡ªå®šä¹‰-i2v-lora-æ•ˆæœè®­ç»ƒ)
    - [è¦æ±‚](#è¦æ±‚)
    - [è®­ç»ƒç¯å¢ƒ](#è®­ç»ƒç¯å¢ƒ)
    - [è®­ç»ƒæ•°æ®æ„å»º](#è®­ç»ƒæ•°æ®æ„å»º)
    - [å¼€å§‹è®­ç»ƒ](#å¼€å§‹è®­ç»ƒ)
    - [æ¨ç†](#æ¨ç†)
  - [ğŸ”— BibTeX](#-bibtex)
  - [è‡´è°¢](#è‡´è°¢)

---

## **HunyuanVideo-I2V æ•´ä½“æ¶æ„**
åŸºäº[HunyuanVideo](https://github.com/Tencent/HunyuanVideo)å¼ºå¤§çš„è§†é¢‘ç”Ÿæˆèƒ½åŠ›ï¼Œæˆ‘ä»¬å°†å…¶æ‰©å±•è‡³å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨å›¾åƒéšç©ºé—´æ‹¼æ¥æŠ€æœ¯ï¼Œæœ‰æ•ˆé‡æ„å¹¶èåˆå‚è€ƒå›¾åƒä¿¡æ¯è‡³è§†é¢‘ç”Ÿæˆæµç¨‹ä¸­ã€‚

ç”±äºæˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„Decoder-Onlyæ¶æ„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œå¯ç”¨äºæ˜¾è‘—å¢å¼ºæ¨¡å‹å¯¹è¾“å…¥å›¾åƒè¯­ä¹‰å†…å®¹çš„ç†è§£èƒ½åŠ›ï¼Œå¹¶å®ç°å›¾åƒä¸æ–‡æœ¬æè¿°ä¿¡æ¯çš„æ·±åº¦èåˆã€‚å…·ä½“è€Œè¨€ï¼Œè¾“å…¥å›¾åƒç»MLLMå¤„ç†åç”Ÿæˆè¯­ä¹‰å›¾åƒtokensï¼Œè¿™äº›tokensä¸è§†é¢‘éšç©ºé—´tokensæ‹¼æ¥ï¼Œå®ç°è·¨æ¨¡æ€çš„å…¨æ³¨æ„åŠ›è®¡ç®—ã€‚

æˆ‘ä»¬çš„ç³»ç»Ÿæ¶æ„æ—¨åœ¨æœ€å¤§åŒ–å›¾åƒä¸æ–‡æœ¬æ¨¡æ€çš„ååŒæ•ˆåº”ï¼Œç¡®ä¿ä»é™æ€å›¾åƒç”Ÿæˆè¿è´¯çš„è§†é¢‘å†…å®¹ã€‚è¯¥é›†æˆä¸ä»…æå‡äº†ç”Ÿæˆè§†é¢‘çš„ä¿çœŸåº¦ï¼Œè¿˜å¢å¼ºäº†æ¨¡å‹å¯¹å¤æ‚å¤šæ¨¡æ€è¾“å…¥çš„è§£æèƒ½åŠ›ã€‚æ•´ä½“æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
<p align="center">
  <img src="./assets/backbone.png"  height=300>
</p>

## ğŸ“œ è¿è¡Œè¦æ±‚

ä¸‹è¡¨å±•ç¤ºäº†è¿è¡ŒHunyuanVideo-I2Væ¨¡å‹ï¼ˆbatch size=1ï¼‰ç”Ÿæˆè§†é¢‘çš„ç¡¬ä»¶è¦æ±‚ï¼š

|      æ¨¡å‹       | åˆ†è¾¨ç‡  | GPUæ˜¾å­˜å³°å€¼ |
|:---------------:|:-------:|:-----------:|
| HunyuanVideo-I2V |  720p   |    60GB     |

* éœ€é…å¤‡æ”¯æŒCUDAçš„NVIDIA GPU
  * æµ‹è¯•ç¯å¢ƒä¸ºå•å¡80G GPU
  * **æœ€ä½è¦æ±‚**: 720påˆ†è¾¨ç‡éœ€è‡³å°‘60GBæ˜¾å­˜
  * **æ¨èé…ç½®**: å»ºè®®ä½¿ç”¨80GBæ˜¾å­˜GPUä»¥è·å¾—æ›´ä½³ç”Ÿæˆè´¨é‡
* æµ‹è¯•æ“ä½œç³»ç»Ÿï¼šLinux

## ğŸ› ï¸ ä¾èµ–å®‰è£…

é¦–å…ˆå…‹éš†ä»“åº“ï¼š
```shell
git clone https://github.com/tencent/HunyuanVideo-I2V
cd HunyuanVideo-I2V
```

### Linux å®‰è£…æŒ‡å¼•

æˆ‘ä»¬æ¨èä½¿ç”¨ CUDA 12.4 æˆ– 11.8 çš„ç‰ˆæœ¬ã€‚

Conda çš„å®‰è£…æŒ‡å—å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://docs.anaconda.com/free/miniconda/index.html)ã€‚

```shell
# 1. åˆ›å»ºcondaç¯å¢ƒ
conda create -n HunyuanVideo-I2V python==3.11.9

# 2. æ¿€æ´»ç¯å¢ƒ
conda activate HunyuanVideo-I2V

# 3. é€šè¿‡condaå®‰è£…PyTorchç­‰ä¾èµ–
# CUDA 12.4ç‰ˆæœ¬
conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=12.4 -c pytorch -c nvidia

# 4. å®‰è£…pipä¾èµ–
python -m pip install -r requirements.txt

# 5. å®‰è£…flash attention v2åŠ é€Ÿï¼ˆéœ€CUDA 11.8åŠä»¥ä¸Šï¼‰
python -m pip install ninja
python -m pip install git+https://github.com/Dao-AILab/flash-attention.git@v2.6.3
```

å¦‚æœåœ¨ç‰¹å®š GPU å‹å·ä¸Šé­é‡ float point exception(core dump) é—®é¢˜ï¼Œå¯å°è¯•ä»¥ä¸‹æ–¹æ¡ˆä¿®å¤ï¼š

```shell
# ç¡®ä¿å·²å®‰è£…CUDA 12.4ã€CUBLAS>=12.4.5.8å’ŒCUDNN>=9.00ï¼ˆæˆ–ç›´æ¥ä½¿ç”¨æˆ‘ä»¬çš„CUDA 12 dockeré•œåƒï¼‰
pip install nvidia-cublas-cu12==12.4.5.8
export LD_LIBRARY_PATH=/opt/conda/lib/python3.8/site-packages/nvidia/cublas/lib/
```

å¦å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªé¢„æ„å»ºçš„ Docker é•œåƒï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œæ‹‰å–å’Œè¿è¡Œã€‚
```shell
# CUDA 12.4é•œåƒï¼ˆé¿å…æµ®ç‚¹å¼‚å¸¸ï¼‰
docker pull hunyuanvideo/hunyuanvideo-i2v:cuda_12
docker run -itd --gpus all --init --net=host --uts=host --ipc=host --name hunyuanvideo-i2v --security-opt=seccomp=unconfined --ulimit=stack=67108864 --ulimit=memlock=-1 --privileged hunyuanvideo/hunyuanvideo-i2v:cuda_12
```

## ğŸ§± ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯è¯·å‚è§ [here](ckpts/README.md)ã€‚

## ğŸ”‘ å• GPU æ¨ç†

ç±»ä¼¼äº [HunyuanVideo](https://github.com/Tencent/HunyuanVideo)ï¼ŒHunyuanVideo-I2V æ”¯æŒé«˜åˆ†è¾¨ç‡è§†é¢‘ç”Ÿæˆï¼Œåˆ†è¾¨ç‡æœ€é«˜å¯è¾¾ 720Pï¼Œè§†é¢‘é•¿åº¦æœ€é«˜å¯è¾¾ 129 å¸§ï¼ˆ5 ç§’ï¼‰ã€‚
### ä½¿ç”¨å›¾ç”Ÿè§†é¢‘æ¨¡å‹çš„å»ºè®®

- **ä½¿ç”¨ç®€çŸ­çš„æç¤º**ï¼šä¸ºäº†æœ‰æ•ˆåœ°å¼•å¯¼æ¨¡å‹çš„ç”Ÿæˆï¼Œè¯·ä¿æŒæç¤ºç®€çŸ­ä¸”ç›´æˆªäº†å½“ã€‚
- **åŒ…å«å…³é”®å…ƒç´ **ï¼šä¸€ä¸ªç»“æ„è‰¯å¥½çš„æç¤ºåº”åŒ…æ‹¬ï¼š
  - **ä¸»ä½“**ï¼šæŒ‡å®šè§†é¢‘çš„ä¸»è¦ç„¦ç‚¹ã€‚
  - **åŠ¨ä½œ**ï¼šæè¿°æ­£åœ¨å‘ç”Ÿçš„è¿åŠ¨æˆ–æ´»åŠ¨ã€‚
  - **èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰**ï¼šè®¾ç½®è§†é¢‘çš„åœºæ™¯ã€‚
  - **é•œå¤´ï¼ˆå¯é€‰ï¼‰**ï¼šæŒ‡ç¤ºè§†è§’æˆ–è§†ç‚¹ã€‚
- **é¿å…è¿‡äºè¯¦ç»†çš„æç¤º**ï¼šå†—é•¿æˆ–é«˜åº¦è¯¦ç»†çš„æç¤ºå¯èƒ½ä¼šå¯¼è‡´è§†é¢‘è¾“å‡ºä¸­å‡ºç°ä¸å¿…è¦çš„è½¬åœºã€‚

### ä½¿ç”¨å‘½ä»¤è¡Œ

```bash
cd HunyuanVideo-I2V

python3 sample_image2video.py \
    --model HYVideo-T/2 \
    --prompt "A man with short gray hair plays a red electric guitar." \
    --i2v-mode \
    --i2v-image-path ./assets/demo/i2v/imgs/0.png \
    --i2v-resolution 720p \
    --video-length 129 \
    --infer-steps 50 \
    --flow-reverse \
    --flow-shift 17.0 \
    --seed 0 \
    --use-cpu-offload \
    --save-path ./results 
```
<!-- # ### è¿è¡ŒgradioæœåŠ¡
# ```bash
# python3 gradio_server.py --flow-reverse

# # set SERVER_NAME and SERVER_PORT manually
# # SERVER_NAME=0.0.0.0 SERVER_PORT=8081 python3 gradio_server.py --flow-reverse
# ``` -->

### æ›´å¤šé…ç½®

æˆ‘ä»¬åˆ—å‡ºäº†ä¸€äº›å¸¸ç”¨çš„é…ç½®ä»¥æ–¹ä¾¿ä½¿ç”¨ï¼š

|        å‚æ•°        |            é»˜è®¤            |                          æè¿°                          |
|:----------------------:|:-----------------------------:|:------------------------------------------------------------:|
|       `--prompt`       |             None              |           ç”¨äºè§†é¢‘ç”Ÿæˆçš„æ–‡æœ¬æç¤ºã€‚               |
|       `--model`        |      HYVideo-T/2-cfgdistill   | è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ HYVideo-T/2 ç”¨äº I2Vï¼ŒHYVideo-T/2-cfgdistill ç”¨äº T2V æ¨¡å¼ã€‚ |
|     `--i2v-mode`       |            False              |                æ˜¯å¦å¼€å¯ I2V æ¨¡å¼ã€‚                      |
|  `--i2v-image-path`    | ./assets/demo/i2v/imgs/0.png  |        ç”¨äºè§†é¢‘ç”Ÿæˆçš„å‚è€ƒå›¾åƒã€‚              |
|  `--i2v-resolution`    |            720p               |        ç”Ÿæˆè§†é¢‘çš„åˆ†è¾¨ç‡ã€‚                |
|    `--video-length`    |             129               |         ç”Ÿæˆè§†é¢‘çš„é•¿åº¦ã€‚                    |
|    `--infer-steps`     |              50               |         é‡‡æ ·æ­¥éª¤çš„æ•°é‡ã€‚                     |
|     `--flow-shift`     |             7.0               |     æµåŒ¹é…è°ƒåº¦å™¨çš„åç§»å› å­ã€‚               |
|   `--flow-reverse`     |            False              | å¦‚æœåè½¬ï¼Œä» t=1 å­¦ä¹ /é‡‡æ ·åˆ° t=0ã€‚                |
|        `--seed`        |             None              | ç”Ÿæˆè§†é¢‘çš„éšæœºç§å­ï¼Œå¦‚æœä¸º Noneï¼Œåˆ™åˆå§‹åŒ–ä¸€ä¸ªéšæœºç§å­ã€‚ |
|  `--use-cpu-offload`   |            False              | ä½¿ç”¨ CPU å¸è½½æ¨¡å‹åŠ è½½ä»¥èŠ‚çœæ›´å¤šå†…å­˜ï¼Œå¯¹äºé«˜åˆ†è¾¨ç‡è§†é¢‘ç”Ÿæˆæ˜¯å¿…è¦çš„ã€‚ |
|     `--save-path`      |         ./results             |         ä¿å­˜ç”Ÿæˆè§†é¢‘çš„è·¯å¾„ã€‚                     |


## ğŸ‰è‡ªå®šä¹‰ I2V LoRA æ•ˆæœè®­ç»ƒ

###  è¦æ±‚

ä¸‹è¡¨æ˜¾ç¤ºäº†è®­ç»ƒ HunyuanVideo-I2V lora æ¨¡å‹ï¼ˆæ‰¹é‡å¤§å° = 1ï¼‰ä»¥ç”Ÿæˆè§†é¢‘çš„è¦æ±‚ï¼š

|      æ¨¡å‹       | åˆ†è¾¨ç‡ | GPU å³°å€¼å†…å­˜ |
|:----------------:|:----------:|:---------------:|
| HunyuanVideo-I2V |    360p    |      79GB       |

* éœ€è¦æ”¯æŒ CUDA çš„ NVIDIA GPUã€‚
  * è¯¥æ¨¡å‹åœ¨å•ä¸ª 80G GPU ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚
  * **æœ€ä½è¦æ±‚**: ç”Ÿæˆ 360p è§†é¢‘æ‰€éœ€çš„æœ€å° GPU å†…å­˜ä¸º 79GBã€‚
  * **æ¨è**: å»ºè®®ä½¿ç”¨ 80GB å†…å­˜çš„ GPU ä»¥è·å¾—æ›´å¥½çš„ç”Ÿæˆè´¨é‡ã€‚
* æµ‹è¯•æ“ä½œç³»ç»Ÿ: Linux
* æ³¨æ„: æ‚¨å¯ä»¥ä½¿ç”¨ 360p æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ç›´æ¥æ¨æ–­ 540p è§†é¢‘

### è®­ç»ƒç¯å¢ƒ
```
pip install -r requirements.txt
```

### è®­ç»ƒæ•°æ®æ„å»º
æç¤ºæè¿°ï¼šè§¦å‘è¯ç›´æ¥å†™åœ¨è§†é¢‘è¯´æ˜ä¸­ã€‚å»ºè®®ä½¿ç”¨çŸ­è¯­æˆ–ç®€çŸ­å¥å­ã€‚

ä¾‹å¦‚ï¼ŒAI å¤´å‘ç”Ÿé•¿æ•ˆæœï¼ˆè§¦å‘è¯ï¼‰ï¼šrapid_hair_growth, The hair of the characters in the video is growing rapidly. + åŸå§‹æç¤º

å‡†å¤‡å¥½è®­ç»ƒè§†é¢‘å’Œæç¤ºå¯¹åï¼Œå‚è€ƒ [è¿™é‡Œ] (hyvideo/hyvae_extract/README.md) è¿›è¡Œè®­ç»ƒæ•°æ®æ„å»ºã€‚


### å¼€å§‹è®­ç»ƒ
```
sh scripts/run_train_image2video_lora.sh
```
æˆ‘ä»¬åˆ—å‡ºäº†ä¸€äº›è®­ç»ƒç‰¹å®šé…ç½®ä»¥æ–¹ä¾¿ä½¿ç”¨ï¼š

|     å‚æ•°     |                            é»˜è®¤                            |                         æè¿°                         |
|:----------------:|:-------------------------------------------------------------:|:-----------------------------------------------------------:|
|   `SAVE_BASE`    |                               .                               |         ä¿å­˜å®éªŒç»“æœçš„æ ¹è·¯å¾„ã€‚          |
|    `EXP_NAME`    |                           i2v_lora                            |        ä¿å­˜å®éªŒç»“æœçš„è·¯å¾„åç¼€ã€‚         |
| `DATA_JSONS_DIR` | ./assets/demo/i2v_lora/train_dataset/processed_data/json_path | ç”± hyvideo/hyvae_extract/start.sh ç”Ÿæˆçš„æ•°æ® jsons ç›®å½•ã€‚ |
|    `CHIEF_IP`    |                            0.0.0.0                            |            ä¸»èŠ‚ç‚¹ IP åœ°å€ã€‚                   |

### æ¨ç†
```bash
python3 sample_image2video.py \
    --model HYVideo-T/2 \
    --prompt "Two people hugged tightly, In the video, two people are standing apart from each other. They then move closer to each other and begin to hug tightly. The hug is very affectionate, with the two people holding each other tightly and looking into each other's eyes. The interaction is very emotional and heartwarming, with the two people expressing their love and affection for each other." \
    --i2v-mode \
    --i2v-image-path ./assets/demo/i2v_lora/imgs/embrace.png \
    --i2v-resolution 540p \
    --infer-steps 50 \
    --video-length 129 \
    --flow-reverse \
    --flow-shift 5.0 \
    --seed 0 \
    --use-cpu-offload \
    --save-path ./results \
    --use-lora \
    --lora-scale 1.0 \
    --lora-path ./ckpts/hunyuan-video-i2v-720p/lora/embrace_kohaya_weights.safetensors \
```
æˆ‘ä»¬åˆ—å‡ºäº†ä¸€äº› LoRA ç‰¹å®šé…ç½®ä»¥æ–¹ä¾¿ä½¿ç”¨ï¼š

|      å‚æ•°       | é»˜è®¤ |         æè¿°          |
|:-------------------:|:-------:|:----------------------------:|
|    `--use-lora`     |  None   |  æ˜¯å¦å¼€å¯ LoRA æ¨¡å¼ã€‚  |
|   `--lora-scale`    |   1.0   | LoRA æ¨¡å‹çš„èåˆæ¯”ä¾‹ã€‚ |
|   `--lora-path`     |   ""    |  LoRA æ¨¡å‹çš„æƒé‡è·¯å¾„ã€‚ |

## ğŸ”— BibTeX

å¦‚æœæ‚¨å‘ç° [HunyuanVideo](https://arxiv.org/abs/2412.03603) å¯¹æ‚¨çš„ç ”ç©¶å’Œåº”ç”¨æœ‰æ‰€å¸®åŠ©ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ BibTeX å¼•ç”¨ï¼š

```BibTeX
@misc{kong2024hunyuanvideo,
      title={HunyuanVideo: A Systematic Framework For Large Video Generative Models}, 
      author={Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo Wu, Jianwei Zhang, Kathrina Wu, Qin Lin, Aladdin Wang, Andong Wang, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Hongmei Wang, Jacob Song, Jiawang Bai, Jianbing Wu, Jinbao Xue, Joey Wang, Junkun Yuan, Kai Wang, Mengyang Liu, Pengyu Li, Shuai Li, Weiyan Wang, Wenqing Yu, Xinchi Deng, Yang Li, Yanxin Long, Yi Chen, Yutao Cui, Yuanbo Peng, Zhentao Yu, Zhiyu He, Zhiyong Xu, Zixiang Zhou, Zunnan Xu, Yangyu Tao, Qinglin Lu, Songtao Liu, Dax Zhou, Hongfa Wang, Yong Yang, Di Wang, Yuhong Liu, and Jie Jiang, along with Caesar Zhong},
      year={2024},
      archivePrefix={arXiv preprint arXiv:2412.03603},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.03603}, 
}
```

## è‡´è°¢

HunyuanVideo çš„å¼€æºç¦»ä¸å¼€è¯¸å¤šå¼€æºå·¥ä½œï¼Œè¿™é‡Œæˆ‘ä»¬ç‰¹åˆ«æ„Ÿè°¢ [SD3](https://huggingface.co/stabilityai/stable-diffusion-3-medium), [FLUX](https://github.com/black-forest-labs/flux), [Llama](https://github.com/meta-llama/llama), [LLaVA](https://github.com/haotian-liu/LLaVA), [Xtuner](https://github.com/InternLM/xtuner), [diffusers](https://github.com/huggingface/diffusers) and [HuggingFace](https://huggingface.co) çš„å¼€æºå·¥ä½œå’Œæ¢ç´¢ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿæ„Ÿè°¢è…¾è®¯æ··å…ƒå¤šæ¨¡æ€å›¢é˜Ÿå¯¹ HunyuanVideo é€‚é…å¤šç§æ–‡æœ¬ç¼–ç å™¨çš„æ”¯æŒã€‚



<!-- ## Star è¶‹åŠ¿

<a href="https://star-history.com/#Tencent/HunyuanVideo&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/HunyuanVideo&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/HunyuanVideo&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/HunyuanVideo&type=Date" />
 </picture>
</a> -->


<!-- # I2V + lora

## è®­ç»ƒç¯å¢ƒ
```
pip install -r requirements.txt
```

## è®­ç»ƒæ•°æ®æ„é€ 
promptè¯´æ˜: triggerè¯ç›´æ¥å†™åœ¨video captioné‡Œé¢ï¼Œå»ºè®®ç”¨çŸ­è¯­æˆ–çŸ­å¥, æ¯”å¦‚

æ¯”å¦‚aiç”Ÿå‘ç‰¹æ•ˆï¼šrapid_hair_growth, The hair of the characters in the video is growing rapidly. + åŸå§‹prompt

æœ‰äº†è®­ç»ƒè§†é¢‘å’Œpromptå¯¹åï¼Œè®­ç»ƒæ•°æ®æ„é€ å‚è€ƒ[è¿™é‡Œ](hyvideo/hyvae_extract/README.md)ã€‚


## å¯åŠ¨è®­ç»ƒ
```
sh scripts/run_train_image2video_lora.sh
# é‡è¦å‚æ•°
# --data-jsons-path è®­ç»ƒæ•°æ®è·¯å¾„
# --model  è®­ç»ƒåº•æ¨¡
# --output-dir loraå­˜æ”¾ä½ç½®
```

## æ¨ç†
```
sh scripts/run_sample_image2video.sh
# é‡è¦å‚æ•°
# --prompt æ¨ç†prompt
# --i2v-image-path è¾“å…¥å›¾ç‰‡ä½ç½®
# --lora-path å¾…åŠ è½½loraä½ç½®
# --lora-scale loraåŠ è½½æƒé‡
``` -->

